{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, natsort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, LSTM, Dense, LeakyReLU, ReLU, Dropout, PReLU\n",
    "from keras.backend import clear_session\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization\n",
    "from keras.layers import Conv1D, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.layers import PReLU\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from keras.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tensorflow_gpu():\n",
    "    sys_info = tf.sysconfig.get_build_info()\n",
    "    cuda_version, cudnn_version = sys_info['cuda_version'], sys_info['cudnn_version']\n",
    "    num_gpu_avail = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "    gpu_name = device_lib.list_local_devices()[1].physical_device_desc[17:40]\n",
    "    print('Tensorflow built with CUDA?',  tf.test.is_built_with_cuda())\n",
    "    print(\"TF: {} | CUDA: {} | cuDNN: {}\".format(tf.__version__, cuda_version, cudnn_version))\n",
    "    print('# GPU available: {} ({})'.format(num_gpu_avail, gpu_name))\n",
    "check_tensorflow_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Full_Inputs_LSTM_OIPM.csv')\n",
    "data = data.drop(['Unnamed: 10', 'Unnamed: 11'], axis=1)\n",
    "OIPM = np.array(data.pop('OIPM_1')).reshape(-1,1)\n",
    "scaler_OIPM = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_OIPM.fit(OIPM)\n",
    "OIPM_norm = scaler_OIPM.transform(OIPM)\n",
    "OIPM_norm = OIPM_norm.reshape(-1, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_data = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_data.fit(data)\n",
    "data_norm = scaler_data.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = data_norm.shape[0] // 101\n",
    "data_norm = data_norm.reshape(-1, 101, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.any(OIPM_norm != 0, axis=1)\n",
    "labels = labels.astype(int)\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(data_norm, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(101, 9)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "cnn_model = make_cnn_model()\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = cnn_model.fit(X_train_clf, y_train_clf, \n",
    "                    epochs=100,\n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2, \n",
    "                    shuffle=True, \n",
    "                    verbose=0)\n",
    "\n",
    "preds = (cnn_model.predict(X_test_clf) > 0.5).astype(\"int32\")\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_class_0 = preds == 0\n",
    "mask_class_1 = preds == 1\n",
    "\n",
    "P_0 = preds[mask_class_0]\n",
    "P_1 = preds[mask_class_1]\n",
    "print(f\"P_0 shape: {P_0.shape}\")\n",
    "print(f\"P_1 shape: {P_1.shape}\")\n",
    "\n",
    "labels_all = np.any(OIPM_norm != 0, axis=1)\n",
    "labels_all = labels_all.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(data_norm, labels_all, epochs=100, batch_size=128, shuffle=True, verbose=0)\n",
    "preds_all = (cnn_model.predict(data_norm) > 0.5).astype(\"int32\")\n",
    "\n",
    "mask_class_0_all = preds_all == 0\n",
    "mask_class_1_all = preds_all == 1\n",
    "\n",
    "P_0_all = data_norm[mask_class_0_all.squeeze()]\n",
    "P_1_all = data_norm[mask_class_1_all.squeeze()]\n",
    "print(f\"P_0_all shape: {P_0_all.shape}\")\n",
    "print(f\"P_1_all shape: {P_1_all.shape}\")\n",
    "\n",
    "P_1_all_mean = P_1_all.mean(axis=-1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(P_1_all_mean.shape[0]):\n",
    "    plt.plot(P_1_all_mean[i, :], label=f'Realization {i+1}' if i < 10 else None)\n",
    "plt.xlabel('Timestep'); plt.ylabel('Mean value of features')\n",
    "plt.title('P_1_all values for all realizations over time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = (cnn_model.predict(data_norm) > 0.5).astype(\"int32\")\n",
    "\n",
    "mask_class_0_all = preds_all == 0\n",
    "mask_class_1_all = preds_all == 1\n",
    "\n",
    "OIPM_norm_1 = OIPM_norm[mask_class_1_all.squeeze()]\n",
    "data_norm_1 = data_norm[mask_class_1_all.squeeze()]\n",
    "print(f\"data_norm_1 shape: {data_norm_1.shape}\")\n",
    "print(f\"OIPM_norm_1 shape: {OIPM_norm_1.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realization_index = 60\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(OIPM_norm_1[realization_index, :], label=f'Realization {realization_index+1}')\n",
    "plt.xlabel('Timestep'); plt.ylabel('Value')\n",
    "plt.title(f'Temporal Evolution of Realization {realization_index+1}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "for i in range(OIPM_norm_1.shape[0]):\n",
    "    plt.plot(OIPM_norm_1[i, :], label=f'Realization {i+1}')\n",
    "plt.xlabel('Timestep'); plt.ylabel('Value')\n",
    "plt.title('Temporal Evolution of All Realizations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_norm_1.reshape(-1, data_norm_1.shape[-1])\n",
    "data_1 = scaler_data.inverse_transform(data_1)\n",
    "data_1 = data_1.reshape(data_norm_1.shape)\n",
    "\n",
    "OIPM_1 = OIPM_norm_1.reshape(-1, 1)\n",
    "OIPM_1 = scaler_OIPM.inverse_transform(OIPM_1)\n",
    "OIPM_1 = OIPM_1.reshape(OIPM_norm_1.shape)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(OIPM_1.shape[0]):\n",
    "    plt.plot(OIPM_1[i, :])\n",
    "plt.xlabel('Timestep'); plt.ylabel('Value')\n",
    "plt.title('Temporal Evolution of All Realizations unsclaed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_norm_1, OIPM_norm_1, test_size=0.2)\n",
    "print('X_train: {} | y_train: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test:  {} | y_test:  {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_OIPM_model(reg=1e-3, drop=0.1):\n",
    "    clear_session()\n",
    "    def rnn_layer(inp, units):\n",
    "        _ = GRU(units, kernel_regularizer=L2(reg), dropout=drop, return_sequences=True)(inp)\n",
    "        _ = PReLU()(_)\n",
    "        _ = BatchNormalization()(_)\n",
    "        return _\n",
    "    inp = Input(shape=(101,9))\n",
    "    _ = rnn_layer(inp, 16)\n",
    "    _ = rnn_layer(_, 128)\n",
    "    _ = rnn_layer(_, 16)\n",
    "    out = rnn_layer(_, 1)\n",
    "    return Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_OIPM_model()\n",
    "model.compile(optimizer=Nadam(learning_rate=1e-3), loss='mse', metrics=['mse','mae'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=75,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=0)\n",
    "\n",
    "y_train_pred = model.predict(X_train).squeeze()\n",
    "y_test_pred  = model.predict(X_test).squeeze()\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse  = mean_squared_error(y_test, y_test_pred)\n",
    "print('MSE: Train={:.3f} | Test={:.3f}'.format(train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['loss'], color='tab:blue', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='tab:orange', label='val_loss')\n",
    "plt.title('Model Loss'); plt.legend(); plt.grid(True, which='both')\n",
    "plt.ylabel('Loss'); plt.xlabel('Epoch')\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['mse'], 'r-', label='mse')\n",
    "plt.plot(history.history['val_mse'], 'r--', label='val_mse')\n",
    "plt.plot(history.history['mae'], 'g-', label='mae')\n",
    "plt.plot(history.history['val_mae'], 'g--', label='val_mae')\n",
    "plt.legend(); plt.grid(True, which='both')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(np.mean(y_test, axis=0), np.mean(y_test_pred, axis=0), 'k--')\n",
    "plt.xlim([0,0.2]); plt.ylim([0,0.2])\n",
    "plt.title('Mean of Predictions vs. Actual')\n",
    "tstep = 100\n",
    "plt.subplot(122)\n",
    "plt.plot(y_test[:,tstep], y_test_pred[:,tstep], '.')\n",
    "plt.xlabel('True'); plt.ylabel('Pred')\n",
    "plt.xlim([0,1]); plt.ylim([0,1])\n",
    "plt.axline([0,0], [1,1], color='r', linestyle='-')\n",
    "plt.title(f'Predictions vs. Actual at Timestep {tstep}')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = np.linspace(0, 1000, num=101)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "for i in range(10):\n",
    "    k = random.randint(0, 100)\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.plot(timesteps, y_test[k,:], 'tab:blue', label='true')\n",
    "    plt.plot(timesteps, y_test_pred[k,:], 'tab:red', label='pred')\n",
    "    plt.xlabel('time [years]'); plt.ylabel('OIPM')\n",
    "    plt.legend()\n",
    "    plt.title(f'Case {k+1}')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
