{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /mnt/e/H2-Proxy/heterogeneity\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "\n",
    "def check_tensorflow_gpu():\n",
    "    sys_info = tf.sysconfig.get_build_info()\n",
    "    cuda_version, cudnn_version = sys_info['cuda_version'], sys_info['cudnn_version']\n",
    "    num_gpu_avail = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "    gpu_name = device_lib.list_local_devices()[1].physical_device_desc[17:40]\n",
    "    print('... Checking Tensorflow Version ...')\n",
    "    print('Tensorflow built with CUDA?',  tf.test.is_built_with_cuda())\n",
    "    print(\"TF: {} | CUDA: {} | cuDNN: {}\".format(tf.__version__, cuda_version, cudnn_version))\n",
    "    print('# GPU available: {} ({})'.format(num_gpu_avail, gpu_name))\n",
    "    print(tf.config.list_physical_devices())\n",
    "    return None\n",
    "#check_tensorflow_gpu()\n",
    "\n",
    "print('Current Directory: {}'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata_folder = 'h2datag'\\nfile_list = [file for file in os.listdir(data_folder) if file.endswith('.mat')]\\nprint(len(file_list))\\n\\nporo = np.zeros((256,256))\\nperm = np.zeros((256,256))\\npres = np.zeros((60,256,256))\\nsatu = np.zeros((60,256,256))\\ntime = np.zeros((256,256))\\n\\nfor i in range(1,1001):\\n    datax = loadmat('{}/{}UHSS_0.mat'.format(data_folder,i), simplify_cells=True)\\n    poro = datax['PORO']\\n    perm = datax['PERMX']\\n    for j in range(1,61):\\n        data = loadmat('{}/{}UHSS_{}.mat'.format(data_folder,i,j), simplify_cells=True)\\n        pres[j-1,:,:] = data['PRESSURE']\\n        satu[j-1,:,:] = data['YMF_3']*data['SGAS']\\n        time = np.ones((256,256))*j\\n    np.savez('Gdataset/sample_{}.npz'.format(i), poro=poro, perm=perm, pres=pres, sat=satu, time=time)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data_folder = 'h2datag'\n",
    "file_list = [file for file in os.listdir(data_folder) if file.endswith('.mat')]\n",
    "print(len(file_list))\n",
    "\n",
    "poro = np.zeros((256,256))\n",
    "perm = np.zeros((256,256))\n",
    "pres = np.zeros((60,256,256))\n",
    "satu = np.zeros((60,256,256))\n",
    "time = np.zeros((256,256))\n",
    "\n",
    "for i in range(1,1001):\n",
    "    datax = loadmat('{}/{}UHSS_0.mat'.format(data_folder,i), simplify_cells=True)\n",
    "    poro = datax['PORO']\n",
    "    perm = datax['PERMX']\n",
    "    for j in range(1,61):\n",
    "        data = loadmat('{}/{}UHSS_{}.mat'.format(data_folder,i,j), simplify_cells=True)\n",
    "        pres[j-1,:,:] = data['PRESSURE']\n",
    "        satu[j-1,:,:] = data['YMF_3']*data['SGAS']\n",
    "        time = np.ones((256,256))*j\n",
    "    np.savez('Gdataset/sample_{}.npz'.format(i), poro=poro, perm=perm, pres=pres, sat=satu, time=time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE     = 32\n",
    "INPUT_SHAPE    = (256,256,2)\n",
    "IMAGE_SIZE     = 256\n",
    "\n",
    "AUTO           = tf.data.AUTOTUNE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "PATCH_SIZE     = (4,4,4)\n",
    "NUM_PATCHES    = (IMAGE_SIZE // PATCH_SIZE[0]) **2\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS      = 16\n",
    "NUM_LAYERS     = 8\n",
    "\n",
    "EPOCHS         = 50\n",
    "LEARNING_RATE  = 1e-4\n",
    "WEIGHT_DECAY   = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(filters=embed_dim, kernel_size=patch_size, strides=patch_size, padding=\"same\")\n",
    "        self.flatten    = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n",
    "\n",
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(input_dim=num_tokens, output_dim=self.embed_dim)\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "    def call(self, encoded_tokens):\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens    = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens\n",
    "\n",
    "def create_vivit_model(tubelet_embedder=TubeletEmbedding(embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE), \n",
    "                       positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM), \n",
    "                       input_shape=INPUT_SHAPE, transformer_layers=NUM_LAYERS, num_heads=NUM_HEADS, embed_dim=PROJECTION_DIM, \n",
    "                       layer_norm_eps=LAYER_NORM_EPS, attn_dropout=0.1, st_dropout=0.1):\n",
    "    K.clear_session()\n",
    "    def decoder_layer(inp, filters, kernel_size=3, pad='same'):\n",
    "        x = layers.SeparableConv2D(filters, kernel_size=kernel_size, padding=pad)(inp)\n",
    "        x = layers.LayerNormalization(epsilon=layer_norm_eps)(x)\n",
    "        x = layers.PReLU()(x)\n",
    "        x = layers.Conv2DTranspose(filters, kernel_size=kernel_size, padding=pad, strides=2)(x)\n",
    "        x = layers.SpatialDropout2D(st_dropout)(x)\n",
    "        return x\n",
    "\n",
    "    model_inputs    = layers.Input(shape=input_shape, name='model_input')\n",
    "    inputs          = tf.expand_dims(model_inputs, 1)\n",
    "    patches         = tubelet_embedder(inputs)\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "    \n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim//num_heads, dropout=attn_dropout)(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = layers.LayerNormalization(epsilon=layer_norm_eps)(x2)\n",
    "        x3 = keras.Sequential([layers.Dense(units=embed_dim*4, activation=tf.nn.gelu),\n",
    "                               layers.Dense(units=embed_dim,   activation=tf.nn.gelu)])(x3)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "        \n",
    "    time_input = layers.Input(shape=(None,1), name='time_input')\n",
    "    time_input = tf.ones(shape=encoded_patches.shape[1:])*time_input\n",
    "    latent = layers.Concatenate()([encoded_patches, time_input])\n",
    "    \n",
    "    latent_shape = (IMAGE_SIZE//PATCH_SIZE[0], IMAGE_SIZE//PATCH_SIZE[0], latent.shape[-1])\n",
    "    _ = layers.Reshape(target_shape=(latent_shape))(latent)\n",
    "    _ = decoder_layer(_, 16)\n",
    "    _ = decoder_layer(_, 4)\n",
    "        \n",
    "    outputs = layers.Conv2D(2, 3, padding='same', activation='sigmoid')(_)\n",
    "    model = keras.Model(inputs=[model_inputs,time_input], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: 2,267,258 | Output shape: (None, 256, 256, 2)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " model_input (InputLayer)    [(None, 256, 256, 2)]        0         []                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (None, 1, 256, 256, 2)       0         ['model_input[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tubelet_embedding (Tubelet  (None, 4096, 128)            16512     ['tf.expand_dims[1][0]']      \n",
      " Embedding)                                                                                       \n",
      "                                                                                                  \n",
      " positional_encoder (Positi  (None, 4096, 128)            524288    ['tubelet_embedding[3][0]']   \n",
      " onalEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 4096, 128)            256       ['positional_encoder[3][0]']  \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 4096, 128)            66048     ['layer_normalization[1][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[1][0]'] \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 4096, 128)            0         ['multi_head_attention[1][0]',\n",
      "                                                                     'positional_encoder[3][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 4096, 128)            256       ['add[1][0]']                 \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 4096, 128)            131712    ['layer_normalization_1[1][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 4096, 128)            0         ['sequential[1][0]',          \n",
      "                                                                     'add[1][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 4096, 128)            256       ['add_1[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 4096, 128)            66048     ['layer_normalization_2[1][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_2[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 4096, 128)            0         ['multi_head_attention_1[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_1[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 4096, 128)            256       ['add_2[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 4096, 128)            131712    ['layer_normalization_3[1][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 4096, 128)            0         ['sequential_1[1][0]',        \n",
      "                                                                     'add_2[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 4096, 128)            256       ['add_3[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 4096, 128)            66048     ['layer_normalization_4[1][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 4096, 128)            0         ['multi_head_attention_2[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_3[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 4096, 128)            256       ['add_4[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)   (None, 4096, 128)            131712    ['layer_normalization_5[1][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 4096, 128)            0         ['sequential_2[1][0]',        \n",
      "                                                                     'add_4[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 4096, 128)            256       ['add_5[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 4096, 128)            66048     ['layer_normalization_6[1][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_6[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 4096, 128)            0         ['multi_head_attention_3[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_5[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 4096, 128)            256       ['add_6[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)   (None, 4096, 128)            131712    ['layer_normalization_7[1][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 4096, 128)            0         ['sequential_3[1][0]',        \n",
      "                                                                     'add_6[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 4096, 128)            256       ['add_7[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 4096, 128)            66048     ['layer_normalization_8[1][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_8[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 4096, 128)            0         ['multi_head_attention_4[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_7[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, 4096, 128)            256       ['add_8[1][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)   (None, 4096, 128)            131712    ['layer_normalization_9[1][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 4096, 128)            0         ['sequential_4[1][0]',        \n",
      "                                                                     'add_8[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 4096, 128)            256       ['add_9[1][0]']               \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 4096, 128)            66048     ['layer_normalization_10[1][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_10[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 4096, 128)            0         ['multi_head_attention_5[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_9[1][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 4096, 128)            256       ['add_10[1][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)   (None, 4096, 128)            131712    ['layer_normalization_11[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 4096, 128)            0         ['sequential_5[1][0]',        \n",
      "                                                                     'add_10[1][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 4096, 128)            256       ['add_11[1][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 4096, 128)            66048     ['layer_normalization_12[1][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_12[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 4096, 128)            0         ['multi_head_attention_6[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_11[1][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 4096, 128)            256       ['add_12[1][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)   (None, 4096, 128)            131712    ['layer_normalization_13[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 4096, 128)            0         ['sequential_6[1][0]',        \n",
      "                                                                     'add_12[1][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 4096, 128)            256       ['add_13[1][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 4096, 128)            66048     ['layer_normalization_14[1][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_14[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 4096, 128)            0         ['multi_head_attention_7[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_13[1][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 4096, 128)            256       ['add_14[1][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)   (None, 4096, 128)            131712    ['layer_normalization_15[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 4096, 128)            0         ['sequential_7[1][0]',        \n",
      "                                                                     'add_14[1][0]']              \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)        [(None, 4096, 128)]          0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 4096, 256)            0         ['add_15[1][0]',              \n",
      "                                                                     'input_1[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 64, 64, 256)          0         ['concatenate[1][0]']         \n",
      "                                                                                                  \n",
      " separable_conv2d (Separabl  (None, 64, 64, 16)           6416      ['reshape[1][0]']             \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 64, 64, 16)           32        ['separable_conv2d[1][0]']    \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " p_re_lu (PReLU)             (None, 64, 64, 16)           65536     ['layer_normalization_16[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 128, 128, 16)         2320      ['p_re_lu[1][0]']             \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " spatial_dropout2d (Spatial  (None, 128, 128, 16)         0         ['conv2d_transpose[1][0]']    \n",
      " Dropout2D)                                                                                       \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (Separa  (None, 128, 128, 4)          212       ['spatial_dropout2d[1][0]']   \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 128, 128, 4)          8         ['separable_conv2d_1[1][0]']  \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " p_re_lu_1 (PReLU)           (None, 128, 128, 4)          65536     ['layer_normalization_17[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 256, 256, 4)          148       ['p_re_lu_1[1][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (Spati  (None, 256, 256, 4)          0         ['conv2d_transpose_1[1][0]']  \n",
      " alDropout2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 256, 256, 2)          74        ['spatial_dropout2d_1[1][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2267258 (8.65 MB)\n",
      "Trainable params: 2267258 (8.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_vivit_model()\n",
    "print('# Parameters: {:,} | Output shape: {}'.format(model.count_params(), model.layers[-1].output_shape))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'Fdataset/'\n",
    "file_list = [f for f in os.listdir(dataset_path) if f.endswith('.npz')]\n",
    "\n",
    "np.random.shuffle(file_list)\n",
    "\n",
    "train_files = file_list[:750]\n",
    "test_files  = file_list[750:]\n",
    "\n",
    "timesteps   = np.arange(1,61)\n",
    "print(timesteps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest: MSE:\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m | MAPE=\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(mse, mape))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m model, history \u001b[39m=\u001b[39m run_experiment()\n",
      "\u001b[1;32m/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m create_vivit_model()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdamW(learning_rate\u001b[39m=\u001b[39mLEARNING_RATE, weight_decay\u001b[39m=\u001b[39mWEIGHT_DECAY),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m               loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanSquaredError(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                        keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanAbsolutePercentageError(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmape\u001b[39m\u001b[39m\"\u001b[39m)])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit([X_train, timesteps], y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                     epochs           \u001b[39m=\u001b[39m EPOCHS,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                     validation_split \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                     shuffle          \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m                     verbose          \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m _, mse, mape \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(testloader)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/e/H2-Proxy/heterogeneity/main_tf.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest: MSE:\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m | MAPE=\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(mse, mape))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    model = create_vivit_model()\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY),\n",
    "                  loss=keras.losses.MeanSquaredError(name='mse'),\n",
    "                  metrics=[keras.metrics.MeanSquaredError(name=\"mse\"),\n",
    "                           keras.metrics.MeanAbsolutePercentageError(name=\"mape\")])\n",
    "\n",
    "    history = model.fit([X_train, timesteps], y_train,\n",
    "                        epochs           = EPOCHS,\n",
    "                        validation_split = 0.2,\n",
    "                        shuffle          = True,\n",
    "                        verbose          = 0)\n",
    "    _, mse, mape = model.evaluate(testloader)\n",
    "    print('Test: MSE:{:.4f} | MAPE={:.4f}'.format(mse, mape))\n",
    "    return model, history\n",
    "\n",
    "model, history = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
