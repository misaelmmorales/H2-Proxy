{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiscale Residual Spatiotemporal Vision Transformer (MR-ST-ViT | PixFormer)\n",
    "\n",
    "### Misael M. Morales, 2024\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "Torch version: 2.1.2+cu118 | Torch Built with CUDA? True\n",
      "# Device(s) available: 1, Name(s): Quadro M6000 24GB\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "\n",
    "hete = Heterogeneity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hete.make_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hete.trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hete.tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hete.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    '''\n",
    "    Generate a custom dataset from .npz files\n",
    "    (x) porosity, permeability, timesteps\n",
    "    (y) pressure, saturation\n",
    "    '''\n",
    "    def __init__(self, file_paths, transform=None, norm_type:str='MinMax'):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform  = transform\n",
    "        self.tsteps     = 60\n",
    "        self.x_channels = 3\n",
    "        self.y_channels = 2\n",
    "        self.orig_img   = 256\n",
    "        self.half_img   = 64\n",
    "        self.norm_type  = norm_type\n",
    "        self.norm       = self.normalize\n",
    "\n",
    "    def normalize(self, x):\n",
    "        '''\n",
    "        Normalize dataset based on user-defined scheme\n",
    "        '''\n",
    "        x_norm = np.zeros_like(x)\n",
    "        error_msg = 'Invalid normalization scheme: {} | Select [\"None\", \"MinMax\", \"ExtMinMax\", \"Standard\"]'.format(self.norm_type)\n",
    "        for i in range(x.shape[1]):\n",
    "            if self.norm_type == 'MinMax':\n",
    "                x_norm[:,i] = (x[:,i] - x[:,i].min()) / (x[:,i].max() - x[:,i].min())\n",
    "            elif self.norm_type == 'Standard':\n",
    "                x_norm[:,i] = (x[:,i] - x[:,i].mean()) / (x[:,i].std())\n",
    "            elif self.norm_type == 'ExtMinMax':\n",
    "                x_norm[:,i] = (x[:,i] - x[:,i].min()) / (x[:,i].max() - x[:,i].min()) * 2 - 1\n",
    "            elif self.norm_type == 'None':\n",
    "                x_norm = x\n",
    "            else:\n",
    "                raise ValueError(error_msg)\n",
    "        return x_norm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data   = np.load(self.file_paths[idx])\n",
    "        poro   = np.tile(data['poro'], (self.tsteps, 1, 1, 1))\n",
    "        perm   = np.tile(np.log10(data['perm']), (self.tsteps, 1, 1, 1))\n",
    "        tstep  = np.tile(np.arange(1, self.tsteps+1).reshape(self.tsteps, 1, 1, 1), (1, 1, self.orig_img, self.orig_img))\n",
    "        pres   = np.expand_dims(data['pres'], 1)\n",
    "        sat    = np.expand_dims(data['sat'], 1)\n",
    "        X_data = np.concatenate([poro, perm, tstep], axis=1).reshape(-1, self.x_channels, self.orig_img, self.orig_img)\n",
    "        y_data = np.concatenate([pres, sat], axis=1).reshape(-1, self.y_channels, self.orig_img, self.orig_img)\n",
    "        if self.transform:\n",
    "            X_data_t = np.zeros((len(X_data), self.x_channels, self.half_img, self.half_img))\n",
    "            y_data_t = np.zeros((len(y_data), self.y_channels, self.half_img, self.half_img))\n",
    "            for i in range(len(X_data)):\n",
    "                X_data_t[i] = self.transform(X_data[i].T)\n",
    "                y_data_t[i] = self.transform(y_data[i].T)\n",
    "            X_data, y_data = X_data_t, y_data_t\n",
    "        x, y = torch.Tensor(self.norm(X_data)), torch.Tensor(self.norm(y_data))\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataLoader(DataLoader):\n",
    "    '''\n",
    "    Generate a custom dataloader for dataset\n",
    "    (train): x,y at timesteps 0-40\n",
    "    (valid): x,y at timesteps 40-50\n",
    "    (test):  x,y at timesteps 50-60\n",
    "    '''\n",
    "    def __init__(self, *args, mode:str=None, **kwargs):\n",
    "        super(MyDataLoader, self).__init__(*args, num_workers=8, pin_memory=True, **kwargs)\n",
    "        self.mode = mode\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in super(MyDataLoader, self).__iter__():\n",
    "            X_data, y_data = batch          # loads a batch of data with shate (b, t, c, h, w)\n",
    "            if self.mode == 'train':        # _____TRAINING_____\n",
    "                X_data = X_data[:, :40]     # x at timesteps 0-40\n",
    "                y_data = y_data[:, :40]     # y at timesteps 0-40\n",
    "            elif self.mode == 'valid':      # _____VALIDATION_____\n",
    "                X_data = X_data[:, 40:50]   # x at timesteps 40-50\n",
    "                y_data = y_data[:, 40:50]   # y at timesteps 40-50\n",
    "            elif self.mode == 'test':       # ______TESTING______\n",
    "                X_data = X_data[:, 50:]     # x at timesteps 50-60\n",
    "                y_data = y_data[:, 50:]     # y at timesteps 50-60\n",
    "            else:\n",
    "                raise ValueError('Invalid mode: {} | select between \"train\", \"valid\" or \"test\"'.format(self.mode))\n",
    "            X_data = X_data[:, ::X_data.shape[1]//10]\n",
    "            y_data = y_data[:, ::y_data.shape[1]//10]\n",
    "            X_data = X_data.reshape(-1, X_data.size(2), X_data.size(3), X_data.size(4)) # reshape to (b*t, c, h, w)\n",
    "            y_data = y_data.reshape(-1, y_data.size(2), y_data.size(3), y_data.size(4)) # reshape to (b*t, c, h, w)\n",
    "            yield X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir('Fdataset')\n",
    "file_paths = [os.path.join('Fdataset', file_name) for file_name in file_names]\n",
    "\n",
    "dataset = MyDataset(file_paths)\n",
    "train_size = int(0.5*len(dataset))\n",
    "valid_size = int(0.25*len(dataset))\n",
    "test_size = int(0.25*len(dataset))\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "train_loader = MyDataLoader(train_dataset, batch_size=32, mode='train')\n",
    "valid_loader = MyDataLoader(valid_dataset, batch_size=32, mode='valid')\n",
    "test_loader = MyDataLoader(test_dataset, batch_size=32, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 15172, 10664, 17652, 12804, 9324, 14040, 23376, 13504) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     12\u001b[0m epoch_loss, epoch_ssim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     15\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(x)\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mMyDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(MyDataLoader, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m():\n\u001b[0;32m     14\u001b[0m         X_data, y_data \u001b[38;5;241m=\u001b[39m batch          \u001b[38;5;66;03m# loads a batch of data with shate (b, t, c, h, w)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:        \u001b[38;5;66;03m# _____TRAINING_____\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 15172, 10664, 17652, 12804, 9324, 14040, 23376, 13504) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "model = PixFormer()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = CustomLoss()\n",
    "\n",
    "train_loss, valid_loss, train_ssim, valid_ssim = [], [], [], []\n",
    "best_val_loss, best_model = float('inf'), None\n",
    "time0 = time.time()\n",
    "\n",
    "for epoch in range(10):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    epoch_loss, epoch_ssim = 0.0, 0.0\n",
    "    for i, (x,y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_ssim += 1.0 - criterion.ssim(y_pred,y)\n",
    "    train_loss.append(epoch_loss/(i+1))\n",
    "    train_ssim.append(epoch_ssim/(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
