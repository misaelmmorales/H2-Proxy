{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "------------------ VERSION INFO -----------------\n",
      "Conda Environment: torchy | Python version: 3.8.16 (default, Mar  2 2023, 03:18:16) [MSC v.1916 64 bit (AMD64)]\n",
      "Torch version: 2.0.1\n",
      "Torch build with CUDA? True\n",
      "# Device(s) available: 1, Name(s): Quadro P520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "hete = Heterogeneity()\n",
    "hete.check_torch_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations = 5\n",
    "n_timesteps    = 61\n",
    "dim            = 256\n",
    "\n",
    "pressure, sat_h2 = np.zeros((n_realizations,n_timesteps,dim,dim,1)), np.zeros((n_realizations,n_timesteps,dim,dim,1))\n",
    "poro,     perm   = np.zeros((n_realizations,dim,dim,1)),             np.zeros((n_realizations,dim,dim,1))\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    data0 = loadmat('//dcstorage.lanl.gov/MFR2/misael/h2dataf/{}UHSS_0'.format(i+1))\n",
    "    poro[i], perm[i] = data0['PORO'], data0['PERMX']\n",
    "    for j in range(n_timesteps):\n",
    "        data = loadmat('//dcstorage.lanl.gov/MFR2/misael/h2dataf/{}UHSS_{}'.format(i+1,j))\n",
    "        pressure[i,j] = data['PRESSURE']\n",
    "        sat_h2[i,j]   = data['SGAS'] * data['YMF_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facies shape: (1000, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 256, 256, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facies = np.expand_dims(hete.load_facies()[:n_realizations],-1)\n",
    "facies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61,) (5, 61, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "t_steps = np.arange(61)\n",
    "times = np.ones((n_realizations,61,256,256,1))\n",
    "\n",
    "for i in range(61):\n",
    "    times[:,i] = times[:,i]*t_steps[i]\n",
    "\n",
    "print(t_steps.shape, times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (305, 4, 256, 256) | y: (305, 2, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate([np.repeat(np.concatenate([poro,perm,facies], -1)[:,np.newaxis,...], n_timesteps, axis=1),times],-1).reshape(n_realizations*n_timesteps,dim,dim,4)\n",
    "y_train = np.concatenate([sat_h2, pressure],-1).reshape(n_realizations*n_timesteps,dim,dim,2)\n",
    "\n",
    "X_train = np.moveaxis(X_train, -1, 1)\n",
    "y_train = np.moveaxis(y_train, -1, 1)\n",
    "\n",
    "print('X: {} | y: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_convolution(in_channels, out_channels):\n",
    "    conv_op = Sequential(\n",
    "        Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        ReLU(inplace=True),\n",
    "        Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "        ReLU(inplace=True))\n",
    "    return conv_op\n",
    "\n",
    "class h2_hete_rom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(h2_hete_rom, self).__init__()\n",
    "        \n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.down_convolution_1 = double_convolution(4, 16)\n",
    "        self.down_convolution_2 = double_convolution(16, 32)\n",
    "        self.down_convolution_3 = double_convolution(32, 64)\n",
    "        self.down_convolution_4 = double_convolution(64, 128)\n",
    "        self.down_convolution_5 = double_convolution(128, 256)\n",
    "\n",
    "        self.up_transpose_1   = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up_convolution_1 = double_convolution(256, 128)\n",
    "        self.up_transpose_2   = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up_convolution_2 = double_convolution(128, 64)\n",
    "        self.up_transpose_3   = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.up_convolution_3 = double_convolution(64, 32)\n",
    "        self.up_transpose_4   = nn.ConvTranspose2d(32, 16, kernel_size=2,  stride=2)\n",
    "        self.up_convolution_4 = double_convolution(32, 16)\n",
    "\n",
    "        self.out = nn.Conv2d(16, 2, kernel_size=1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        down_1 = self.down_convolution_1(x)\n",
    "        down_2 = self.max_pool2d(down_1)\n",
    "        down_3 = self.down_convolution_2(down_2)\n",
    "        down_4 = self.max_pool2d(down_3)\n",
    "        down_5 = self.down_convolution_3(down_4)\n",
    "        down_6 = self.max_pool2d(down_5)\n",
    "        down_7 = self.down_convolution_4(down_6)\n",
    "        down_8 = self.max_pool2d(down_7)\n",
    "        down_9 = self.down_convolution_5(down_8)        \n",
    "        \n",
    "        up_1 = self.up_transpose_1(down_9)\n",
    "        x    = self.up_convolution_1(torch.cat([down_7, up_1], 1))\n",
    "        up_2 = self.up_transpose_2(x)\n",
    "        x    = self.up_convolution_2(torch.cat([down_5, up_2], 1))\n",
    "        up_3 = self.up_transpose_3(x)\n",
    "        x    = self.up_convolution_3(torch.cat([down_3, up_3], 1))\n",
    "        up_4 = self.up_transpose_4(x)\n",
    "        x    = self.up_convolution_4(torch.cat([down_1, up_4], 1))\n",
    "        out   = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 154.00 MiB (GPU 0; 4.00 GiB total capacity; 2.70 GiB already allocated; 0 bytes free; 2.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m      7\u001b[0m X_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(X_train)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> 8\u001b[0m y_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mTensor(y_train)\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     10\u001b[0m loss, val_loss \u001b[39m=\u001b[39m [], []\n\u001b[0;32m     11\u001b[0m metrics \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m:[], \u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m:[]}\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 154.00 MiB (GPU 0; 4.00 GiB total capacity; 2.70 GiB already allocated; 0 bytes free; 2.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "rom = h2_hete_rom().to(device)\n",
    "optimizer = NAdam(rom.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "X_train = torch.Tensor(X_train).to(device)\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "\n",
    "loss, val_loss = [], []\n",
    "metrics = {'loss':[], 'val_loss':[]}\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    rom.train()\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        inp  = X_train[i:i+batch_size]\n",
    "        true = y_train[i:i+batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        pred = rom(inp)\n",
    "        loss = loss_fn(pred,true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()*inp.size(0)\n",
    "    metrics['loss'].append(epoch_loss/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
