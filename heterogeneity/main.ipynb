{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "------------------ VERSION INFO -----------------\n",
      "Conda Environment: torchy | Python version: 3.8.16 (default, Mar  2 2023, 03:18:16) [MSC v.1916 64 bit (AMD64)]\n",
      "Torch version: 2.0.1\n",
      "Torch build with CUDA? True\n",
      "# Device(s) available: 1, Name(s): Quadro P520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "hete = Heterogeneity()\n",
    "hete.check_torch_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = np.load('X_data.npy'), np.load('y_data.npy')\n",
    "\n",
    "xn = np.moveaxis(np.moveaxis(X_data, -2, 1).reshape(2000*61,64,64,4), -1, 1)\n",
    "yn = np.moveaxis(np.moveaxis(y_data, -2, 1).reshape(2000*61,64,64,2), -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters and configurations\n",
    "device = hete.device\n",
    "print('device: {}'.format(device))\n",
    "\n",
    "lr         = 2e-4\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "input_channels_X  = 4\n",
    "output_channels_X = 4\n",
    "output_channels_Y = 2\n",
    "input_channels_Y  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NumpyDataset(xn, yn)\n",
    "dataloader    = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CycleGAN\n",
    "cycle_gan = CycleGAN(input_channels_X, output_channels_Y, input_channels_Y, output_channels_X).to(device)\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss       = nn.MSELoss()\n",
    "cycle_consistency_loss = nn.L1Loss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G   = Adam(cycle_gan.parameters(), lr=lr)\n",
    "optimizer_D_X = Adam(cycle_gan.discriminator_X.parameters(), lr=lr)\n",
    "optimizer_D_Y = Adam(cycle_gan.discriminator_Y.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mfor\u001b[39;00m i, (X, Y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m      3\u001b[0m         X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m         Y \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (X, Y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(X.size(0), 1, 14, 14).to(device)\n",
    "        fake  = torch.zeros(X.size(0), 1, 14, 14).to(device)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        identity_X = cycle_gan.generator_YX(X)\n",
    "        identity_Y = cycle_gan.generator_XY(Y)\n",
    "        loss_identity = cycle_consistency_loss(identity_X, X) + cycle_consistency_loss(identity_Y, Y)\n",
    "\n",
    "        # Adversarial loss\n",
    "        fake_Y, fake_X, reconstructed_X, reconstructed_Y = cycle_gan(X, Y)\n",
    "        loss_GAN_XY = adversarial_loss(cycle_gan.discriminator_Y(fake_Y), valid)\n",
    "        loss_GAN_YX = adversarial_loss(cycle_gan.discriminator_X(fake_X), valid)\n",
    "        loss_GAN = loss_GAN_XY + loss_GAN_YX\n",
    "\n",
    "        # Cycle consistency loss\n",
    "        loss_cycle_X = cycle_consistency_loss(reconstructed_X, X)\n",
    "        loss_cycle_Y = cycle_consistency_loss(reconstructed_Y, Y)\n",
    "        loss_cycle = loss_cycle_X + loss_cycle_Y\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_G = loss_identity + loss_GAN + 10 * loss_cycle\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ----------------------\n",
    "        #  Train Discriminators\n",
    "        # ----------------------\n",
    "\n",
    "        optimizer_D_X.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        loss_real = adversarial_loss(cycle_gan.discriminator_X(X), valid)\n",
    "        # Fake loss\n",
    "        loss_fake = adversarial_loss(cycle_gan.discriminator_X(fake_X.detach()), fake)\n",
    "        # Total discriminator X loss\n",
    "        loss_D_X = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D_X.backward()\n",
    "        optimizer_D_X.step()\n",
    "\n",
    "        optimizer_D_Y.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        loss_real = adversarial_loss(cycle_gan.discriminator_Y(Y), valid)\n",
    "        # Fake loss\n",
    "        loss_fake = adversarial_loss(cycle_gan.discriminator_Y(fake_Y.detach()), fake)\n",
    "        # Total discriminator Y loss\n",
    "        loss_D_Y = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D_Y.backward()\n",
    "        optimizer_D_Y.step()\n",
    "\n",
    "    # Print the losses for monitoring\n",
    "    print('Epoch [{}/{}]: Generator Loss: {:.4f},  Discriminator Loss: {:.4f}'.format(epoch+1, num_epochs, \n",
    "                                                                              loss_G.item(), loss_D_X.item()+loss_D_Y.item()))\n",
    "    \n",
    "    # Save generated images (replace with your own path)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake_Y, _, _, _ = cycle_gan(X, Y)\n",
    "            fake_images = torch.cat((X, fake_Y), dim=0)\n",
    "            save_image(fake_images, f\"generated_images/epoch_{epoch + 1}.png\", nrow=batch_size)\n",
    "\n",
    "# Save the trained models (replace with your own path)\n",
    "torch.save(cycle_gan.generator_XY.state_dict(), 'generator_XY.pth')\n",
    "torch.save(cycle_gan.generator_YX.state_dict(), 'generator_YX.pth')\n",
    "torch.save(cycle_gan.discriminator_X.state_dict(), 'discriminator_X.pth')\n",
    "torch.save(cycle_gan.discriminator_Y.state_dict(), 'discriminator_Y.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
